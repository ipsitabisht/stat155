---
editor_options: 
  markdown: 
    wrap: 72
---

## Information on the dataset

## Dimensions

Number of columns: 20 (not including row number) Number of rows: 114000

## Data Dictionary

**track_id**: the track id associated to the spotify track
**artists**: name of the artist(s) who performed the song
**album_name**: album in which track appears in **popularity**: a range
from 0 to 100, songs closer to 100 are more popular versus songs closer
to 0. **duration_ms**: length of track in millliseconds **explicit**:
whether or not track contains explicit language **danceability**: how
danceable a song is based on a combination of musical features like
tempo, rhythm stability, beat strength, and overall regularity (0 =
least danceable , 10 = most danceable) **energy**: mesaures from 0.0-1.0
and takes into account intensity and activity of track **key**: what key
the track is in where 0 = C, 1 = C#,D#, 2 = D, etc. **loudness**:
measured in decibels(dB) **mode**: indicates tracks modality, whether it
is in major or minor scale, 1 = major, 0 = minor **speechiness**:
detects for spoken works in track, values close to 0.0 indicate non
speech music, 0.33-0.66 represent mix of music and speech, 0.66 and
above are mostly podcasts, audiobooks, etc. **acousticness**: confidence
level of whether track is acoustic or not, 0 indicates low confidence in
acousticness, 1 indicates high level of confidence in acousticness
**instrumentalness**: predicts whether a track has no vocals, tracks
closer to 1.0 indicate more likely to contain no vocals **liveness**:
detects if there is a live audience in the recording, the higher the
value the more likely it is that track was performed live **valence**:
measures the positiveness of a track based on sound
(happy,cheerful,etc), 0 is considered more negative aka sad **tempo**:
meaures the beats per minute as an estimate **track_genre**: the genre
the track belongs to
